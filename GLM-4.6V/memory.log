llama_memory_breakdown_print: | memory breakdown [MiB] | total   free     self   model   context   compute    unaccounted |
llama_memory_breakdown_print: |   - CUDA0 (RTX 3080)   | 20181 =  167 + (16638 = 15128 +     864 +     645) +        3375 |
llama_memory_breakdown_print: |   - CUDA1 (RTX 3080)   | 20181 = 1679 + (17751 = 16371 +     864 +     516) +         749 |
llama_memory_breakdown_print: |   - CUDA2 (RTX 3080)   | 20181 = 1805 + (17625 = 16245 +     864 +     516) +         750 |
llama_memory_breakdown_print: |   - CUDA3 (RTX 3080)   | 20181 = 3545 + (15883 = 14331 +     720 +     832) +         752 |
llama_memory_breakdown_print: |   - Host               |                   605 =   333 +       0 +     272                |
